#!/usr/bin/env node
/**
 * Reads import_bc_wa.sql and generates a migration that UPDATEs capacity_total
 * and metadata for existing locations. Matches by name, provider, and coordinates.
 *
 * Run: node scripts/generate-capacity-update-migration.mjs
 * Output: supabase/migrations/017_update_capacity_from_import.sql
 */

import { readFileSync, writeFileSync } from 'fs';
import { dirname, join } from 'path';
import { fileURLToPath } from 'url';

const __dirname = dirname(fileURLToPath(import.meta.url));
const IMPORT_PATH = join(__dirname, '../supabase/import_bc_wa.sql');
const MIGRATION_PATH = join(__dirname, '../supabase/migrations/017_update_capacity_from_import.sql');

// Match: ('name', 'provider', ST_SetSRID(ST_MakePoint(lon, lat), 4326)::geography, 'type', capacity, 'url', 'metadata'::jsonb)
const ROW_REGEX = /^\s*\('\s*((?:[^']|'')*)\s*',\s*'([^']+)',\s*ST_SetSRID\(ST_MakePoint\((-?\d+\.?\d*),\s*(-?\d+\.?\d*)\),\s*4326\)::geography,\s*'[^']+',\s*(NULL|\d+),\s*'[^']*',\s*'(\{[^]*?\})'::jsonb\s*\)/;

function parseImport(sql) {
  const lines = sql.split('\n');
  const rows = [];
  for (const line of lines) {
    const m = line.match(ROW_REGEX);
    if (m) {
      const [, name, provider, lon, lat, capacityStr, metadataStr] = m;
      const capacity = capacityStr === 'NULL' ? null : parseInt(capacityStr, 10);
      const metadata = metadataStr.replace(/''/g, "'");
      rows.push({
        name: name.replace(/''/g, "'"),
        provider,
        lon: parseFloat(lon),
        lat: parseFloat(lat),
        capacity_total: capacity,
        metadata,
      });
    }
  }
  return rows;
}

function escapeSql(val) {
  if (val == null) return 'NULL';
  return "'" + String(val).replace(/'/g, "''") + "'";
}

function main() {
  const sql = readFileSync(IMPORT_PATH, 'utf8');
  const rows = parseImport(sql);

  if (rows.length === 0) {
    console.error('No rows parsed from import file');
    process.exit(1);
  }

  console.error(`Parsed ${rows.length} rows`);

  const inserts = rows
    .map(
      (r) =>
        `  (${escapeSql(r.name)}, ${escapeSql(r.provider)}, ${r.lon}, ${r.lat}, ${r.capacity_total ?? 'NULL'}, ${escapeSql(r.metadata)})`
    )
    .join(',\n');

  const migration = `-- Update capacity_total and metadata for existing locations
-- Matches import_bc_wa.sql data by name, provider, and coordinates.
-- Run this if you already have locations from a previous import.
-- Generated by: node scripts/generate-capacity-update-migration.mjs

CREATE TEMP TABLE IF NOT EXISTS _import_capacity (
  name TEXT,
  provider TEXT,
  lon DOUBLE PRECISION,
  lat DOUBLE PRECISION,
  capacity_total INT,
  metadata JSONB
);

INSERT INTO _import_capacity (name, provider, lon, lat, capacity_total, metadata) VALUES
${inserts};

UPDATE locations l
SET
  capacity_total = CASE WHEN i.capacity_total IS NOT NULL THEN i.capacity_total ELSE l.capacity_total END,
  metadata = COALESCE(l.metadata, '{}'::jsonb) || COALESCE(i.metadata, '{}'::jsonb)
FROM _import_capacity i
WHERE
  l.name = i.name
  AND l.provider = i.provider
  AND ST_DWithin(
    l.coordinates::geography,
    ST_SetSRID(ST_MakePoint(i.lon, i.lat), 4326)::geography,
    0.001
  );

DROP TABLE IF EXISTS _import_capacity;
`;

  writeFileSync(MIGRATION_PATH, migration);
  console.error(`Wrote ${MIGRATION_PATH}`);
}

main();
